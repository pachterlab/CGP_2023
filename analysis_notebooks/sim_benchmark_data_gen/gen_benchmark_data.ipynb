{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd657a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d4583c2",
   "metadata": {},
   "source": [
    "# **In this notebook we will filter for HVGs/overdispersed genes for benchmark datasets, and save files for clustering methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2ff9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scanpy as sc\n",
    "import anndata\n",
    "import loompy as lp\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2452619-3656-45be-83b7-69167e4fa56c",
   "metadata": {},
   "source": [
    "**Download data and metadata for making benchmark loom and h5 files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --content-disposition https://data.caltech.edu/records/derx2-tsj62/files/proc_looms_bench.tar.gz?download=1\n",
    "!tar -xvf proc_looms_bench.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbce99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362fe6f9",
   "metadata": {},
   "source": [
    "### **Save h5 and loom files with HVGs for clustering methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2fc188e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_thresh(U,S,var_t = 1.5,u_min =0.02,s_min =0.02):\n",
    "    '''\n",
    "    Take in U,S matrices, and find genes that meet var/mean thresh\n",
    "    U,S are cellxgene\n",
    "    '''\n",
    "    var_threshold = var_t\n",
    "    U_mean = U.mean(0)\n",
    "    S_mean = S.mean(0)\n",
    "    U_var = U.var(0)\n",
    "    S_var = S.var(0)\n",
    "\n",
    "    #if l == '/home/tchari/counts/allen_bivi/loom/processed_allen_B02H01A02_raw.loom':\n",
    "    u_min = u_min\n",
    "    s_min =  s_min\n",
    "\n",
    "\n",
    "    fitted_idx = (U_mean > u_min) & (S_mean > s_min) \\\n",
    "    & (((U_var-U_mean)/(U_mean**2)) > var_threshold)\\\n",
    "    & (((S_var-S_mean)/(S_mean**2)) > var_threshold)\\\n",
    "    & (np.abs(np.log(S_mean/U_mean)) < 4) \n",
    "    \n",
    "    \n",
    "    return fitted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a6c8b498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchari/.local/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/tchari/.local/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/home/tchari/.local/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. all genes that pass thresh:  1948\n",
      "No. HVGs that pass thresh:  682\n",
      "682\n",
      "nuclear\n",
      "No. all genes that pass thresh:  2770\n",
      "No. HVGs that pass thresh:  359\n",
      "359\n",
      "No. all genes that pass thresh:  1137\n",
      "No. HVGs that pass thresh:  466\n",
      "466\n",
      "No. all genes that pass thresh:  1193\n",
      "No. HVGs that pass thresh:  357\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "#List of looms for benchmark datasets\n",
    "looms = ['./allen_bivi/loom/processed_allen_A08_raw.loom',\n",
    "        './allen_bivi/loom/processed_allen_B02H01A02_raw.loom',\n",
    "        './scMix/cl3/loom/processed_cl3_raw.loom',\n",
    "        './scMix/cl5/loom/processed_cl5_raw.loom']\n",
    "\n",
    "short = ['allen_b08','allen_b02h01a02','cl3','cl5']\n",
    "\n",
    "\n",
    "#Set number of HVGs to try (based on standard procedure)\n",
    "hvgs = [2000] #[300, 1000, 2000, 4000]\n",
    "\n",
    "!mkdir ./hvg_objs_0215\n",
    "\n",
    "\n",
    "for l,s in zip(looms,short):\n",
    "    ds = lp.connect(l)\n",
    "    S = ds.layers['spliced'][:,:]\n",
    "    U = ds.layers['unspliced'][:,:]\n",
    "    bars = ds.ca['barcode']\n",
    "    subclass = ds.ca['subclass_label']\n",
    "    g_names = ds.ra['gene_name']\n",
    "    ds.close()\n",
    "    \n",
    "    \n",
    "    if l == './allen_bivi/loom/processed_allen_B02H01A02_raw.loom':\n",
    "        X = U.T.copy() #nuclear data\n",
    "        print('nuclear')\n",
    "    else:\n",
    "        X = S.T.copy()\n",
    "    \n",
    "    for h in hvgs:\n",
    "        \n",
    "        # --------- Test NB Thresh ----------\n",
    "        fitted_idx = nb_thresh(U.T,S.T,var_t = 1.5,u_min =0.02,s_min =0.02)\n",
    "        num_chosen = np.sum(fitted_idx)\n",
    "        print('No. all genes that pass thresh: ', num_chosen)\n",
    "        # --------- Test NB Thresh ----------\n",
    "        \n",
    "        #Save loom, h5 files with genes that pass NB Thresh\n",
    "        S_sub = S[fitted_idx,:]\n",
    "        U_sub = U[fitted_idx,:]\n",
    "        g_names_sub = g_names[fitted_idx]\n",
    "        retAdata = anndata.AnnData(\n",
    "            X=S_sub.T,\n",
    "            layers={\n",
    "                'spliced': S_sub.T,\n",
    "                'unspliced': U_sub.T\n",
    "            },\n",
    "            obs=pd.DataFrame({'barcode': bars,'subclass_label':subclass},\n",
    "                             index=bars),\n",
    "            var=pd.DataFrame({'gene_name': g_names_sub},index=g_names_sub)\n",
    "        )\n",
    "\n",
    "        retAdata.write_loom('./hvg_objs_0215/'+s+'_'+str(num_chosen)+'all.loom')\n",
    "        \n",
    "        #h5 files for scMDC\n",
    "        hf = h5py.File('./hvg_objs_0215/'+s+'_'+str(num_chosen)+'all.h5', 'w')\n",
    "        hf.create_dataset('X1', data=U_sub.T)\n",
    "        hf.create_dataset('X2', data=S_sub.T)\n",
    "\n",
    "        uniqs = dict(zip(np.unique(subclass),list(range(len(np.unique(subclass))))))\n",
    "        ys = [uniqs[i] for i in subclass]\n",
    "        hf.create_dataset('Y', data=ys)\n",
    "        hf.close()\n",
    "        \n",
    "        \n",
    "        # --------- Filter 2k HVGs for genes that pass thresh ----------\n",
    "\n",
    "        adata = anndata.AnnData(X=X)\n",
    "        adata.layers[\"counts\"] = adata.X.copy()  # preserve counts\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "        adata.raw = adata\n",
    "        sc.pp.highly_variable_genes(adata, n_top_genes=h) #min_mean=0.0125, max_mean=3, min_disp=0.25 ?\n",
    "        #adata = adata[:, adata.var.highly_variable]\n",
    "        \n",
    "        \n",
    "        S_sub = S[adata.var.highly_variable,:]\n",
    "        U_sub = U[adata.var.highly_variable,:]\n",
    "        g_names_sub = g_names[adata.var.highly_variable]\n",
    "        \n",
    "        #Filtering\n",
    "        fitted_idx = nb_thresh(U_sub.T,S_sub.T,var_t = 1.5,u_min =0.02,s_min =0.02)\n",
    "        num_chosen = np.sum(fitted_idx)\n",
    "        \n",
    "        print('No. HVGs that pass thresh: ', num_chosen)\n",
    "        \n",
    "        S_sub = S_sub[fitted_idx,:]\n",
    "        U_sub = U_sub[fitted_idx,:]\n",
    "        g_names_sub = g_names_sub[fitted_idx]\n",
    "        print(len(g_names_sub))\n",
    "        \n",
    "        retAdata = anndata.AnnData(\n",
    "            X=S_sub.T,\n",
    "            layers={\n",
    "                'spliced': S_sub.T,\n",
    "                'unspliced': U_sub.T\n",
    "            },\n",
    "            obs=pd.DataFrame({'barcode': bars,'subclass_label':subclass},\n",
    "                             index=bars),\n",
    "            var=pd.DataFrame({'gene_name': g_names_sub},index=g_names_sub)\n",
    "        )\n",
    "\n",
    "        retAdata.write_loom('./hvg_objs_0215/'+s+'_'+str(num_chosen)+'hvgs.loom')\n",
    "        \n",
    "        #h5 files for scMDC\n",
    "        hf = h5py.File('./hvg_objs_0215/'+s+'_'+str(num_chosen)+'hvgs.h5', 'w')\n",
    "        hf.create_dataset('X1', data=U_sub.T)\n",
    "        hf.create_dataset('X2', data=S_sub.T)\n",
    "\n",
    "        uniqs = dict(zip(np.unique(subclass),list(range(len(np.unique(subclass))))))\n",
    "        ys = [uniqs[i] for i in subclass]\n",
    "        hf.create_dataset('Y', data=ys)\n",
    "        hf.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f970bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ea2bf384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 814M\r\n",
      "-rw-rw-r--. 1 tchari tchari 495M Feb 15 18:46 allen_b02h01a02_2770all.h5\r\n",
      "-rw-rw-r--. 1 tchari tchari  45M Feb 15 18:46 allen_b02h01a02_2770all.loom\r\n",
      "-rw-rw-r--. 1 tchari tchari  65M Feb 15 18:46 allen_b02h01a02_359hvgs.h5\r\n",
      "-rw-rw-r--. 1 tchari tchari  12M Feb 15 18:46 allen_b02h01a02_359hvgs.loom\r\n",
      "-rw-rw-r--. 1 tchari tchari  85M Feb 15 18:46 allen_b08_1948all.h5\r\n",
      "-rw-rw-r--. 1 tchari tchari  13M Feb 15 18:46 allen_b08_1948all.loom\r\n",
      "-rw-rw-r--. 1 tchari tchari  30M Feb 15 18:46 allen_b08_682hvgs.h5\r\n",
      "-rw-rw-r--. 1 tchari tchari 6.4M Feb 15 18:46 allen_b08_682hvgs.loom\r\n",
      "-rw-rw-r--. 1 tchari tchari 7.9M Feb 15 18:46 cl3_1137all.h5\r\n",
      "-rw-rw-r--. 1 tchari tchari 1.4M Feb 15 18:46 cl3_1137all.loom\r\n",
      "-rw-rw-r--. 1 tchari tchari 3.3M Feb 15 18:46 cl3_466hvgs.h5\r\n",
      "-rw-rw-r--. 1 tchari tchari 869K Feb 15 18:46 cl3_466hvgs.loom\r\n",
      "-rw-rw-r--. 1 tchari tchari  36M Feb 15 18:47 cl5_1193all.h5\r\n",
      "-rw-rw-r--. 1 tchari tchari 4.6M Feb 15 18:47 cl5_1193all.loom\r\n",
      "-rw-rw-r--. 1 tchari tchari  11M Feb 15 18:47 cl5_357hvgs.h5\r\n",
      "-rw-rw-r--. 1 tchari tchari 2.3M Feb 15 18:47 cl5_357hvgs.loom\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ./hvg_objs_0215\n",
    "#!rm -r ./hvg_objs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "56f47261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm ./hvg_objs/meK_looms.tar.gz\n",
    "# !rm ./hvg_objs/meK_h5s.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6600a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d48dd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 24., ...,  1.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that counts didn't get transformed (should be discrete)\n",
    "test = lp.connect('./hvg_objs_0215/allen_b08_682hvgs.loom')\n",
    "testS = test.layers['unspliced'][:,:]\n",
    "testS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "54ed3c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(testS.astype(int) == testS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1c3f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7d93a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1c9b2f9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./hvg_objs_0215/allen_b02h01a02_2770all.loom\n",
      "./hvg_objs_0215/allen_b02h01a02_359hvgs.loom\n",
      "./hvg_objs_0215/allen_b08_1948all.loom\n",
      "./hvg_objs_0215/allen_b08_682hvgs.loom\n",
      "./hvg_objs_0215/cl3_1137all.loom\n",
      "./hvg_objs_0215/cl3_466hvgs.loom\n",
      "./hvg_objs_0215/cl5_1193all.loom\n",
      "./hvg_objs_0215/cl5_357hvgs.loom\n"
     ]
    }
   ],
   "source": [
    "!tar -cvzf ./hvg_objs_0215/meK_looms.tar.gz ./hvg_objs_0215/*.loom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88e2b893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./hvg_objs_0215/allen_b02h01a02_2770all.h5\n",
      "./hvg_objs_0215/allen_b02h01a02_359hvgs.h5\n",
      "./hvg_objs_0215/allen_b08_1948all.h5\n",
      "./hvg_objs_0215/allen_b08_682hvgs.h5\n",
      "./hvg_objs_0215/cl3_1137all.h5\n",
      "./hvg_objs_0215/cl3_466hvgs.h5\n",
      "./hvg_objs_0215/cl5_1193all.h5\n",
      "./hvg_objs_0215/cl5_357hvgs.h5\n"
     ]
    }
   ],
   "source": [
    "!tar -cvzf ./hvg_objs_0215/meK_h5s.tar.gz ./hvg_objs_0215/*.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87eb67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
